{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pth = Path('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_intervals = pl.read_csv(data_pth/ 'grade_timesteps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_intervals = pl.read_csv(data_pth/ 'time_intervals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_intervals_final = time_intervals.group_by('id').agg(pl.col('dt').diff().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(data_pth/'graded_data.csv')\n",
    "area_delta = df[['id','area']].group_by('id').agg(pl.col('area').max()-pl.col('area').min())\n",
    "\n",
    "large_blasto_mask = area_delta['area']>8000\n",
    "\n",
    "selected_ids = area_delta.filter(large_blasto_mask.to_list())['id']\n",
    "\n",
    "final_df = df.filter(df[\"id\"].is_in(selected_ids))']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>dt</th></tr><tr><td>f64</td></tr></thead><tbody><tr><td>0.010597</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1,)\n",
       "Series: 'dt' [f64]\n",
       "[\n",
       "\t0.010597\n",
       "]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_intervals.group_by('id').agg(pl.col('dt').diff().mean()).max()['dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_005, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>dt</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;D2016.06.01_S1327_I149_7&quot;</td><td>0.007032</td></tr><tr><td>&quot;D2016.07.16_S1374_I149_4&quot;</td><td>0.006986</td></tr><tr><td>&quot;D2016.06.24_S1348_I149_4&quot;</td><td>0.007007</td></tr><tr><td>&quot;D2016.02.22_S1235_I149_6&quot;</td><td>0.007009</td></tr><tr><td>&quot;D2016.01.05_S1181_I149_4&quot;</td><td>0.006967</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;D2016.06.24_S1348_I149_8&quot;</td><td>0.007007</td></tr><tr><td>&quot;D2016.02.25_S1241_I149_9&quot;</td><td>0.007057</td></tr><tr><td>&quot;D2016.02.13_S1224_I149_1&quot;</td><td>0.006983</td></tr><tr><td>&quot;D2016.01.28_S1206_I149_6&quot;</td><td>0.007041</td></tr><tr><td>&quot;D2016.07.02_S1359_I149_8&quot;</td><td>0.007016</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_005, 2)\n",
       "┌──────────────────────────┬──────────┐\n",
       "│ id                       ┆ dt       │\n",
       "│ ---                      ┆ ---      │\n",
       "│ str                      ┆ f64      │\n",
       "╞══════════════════════════╪══════════╡\n",
       "│ D2016.06.01_S1327_I149_7 ┆ 0.007032 │\n",
       "│ D2016.07.16_S1374_I149_4 ┆ 0.006986 │\n",
       "│ D2016.06.24_S1348_I149_4 ┆ 0.007007 │\n",
       "│ D2016.02.22_S1235_I149_6 ┆ 0.007009 │\n",
       "│ D2016.01.05_S1181_I149_4 ┆ 0.006967 │\n",
       "│ …                        ┆ …        │\n",
       "│ D2016.06.24_S1348_I149_8 ┆ 0.007007 │\n",
       "│ D2016.02.25_S1241_I149_9 ┆ 0.007057 │\n",
       "│ D2016.02.13_S1224_I149_1 ┆ 0.006983 │\n",
       "│ D2016.01.28_S1206_I149_6 ┆ 0.007041 │\n",
       "│ D2016.07.02_S1359_I149_8 ┆ 0.007016 │\n",
       "└──────────────────────────┴──────────┘"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_intervals.group_by('id').agg(pl.col('dt').diff().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "def get_inflection_points(area):\n",
    "    \n",
    "    x = np.arange(len(area.to_numpy()))\n",
    "    y = area  # Your data here\n",
    "\n",
    "\n",
    "    # Compute the first and second derivatives\n",
    "    dy = np.gradient(y)\n",
    "    d2y = np.gradient(dy)\n",
    "\n",
    "    # Set a threshold for the second derivative\n",
    "    threshold = np.max(d2y) * 0.5\n",
    "\n",
    "    sharp_points, _ = find_peaks(d2y, height=threshold)\n",
    "    \n",
    "    return sharp_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.083333333333334"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_intervals_final.filter(pl.col(\"id\") == \"D2016.07.02_S1360_I149_3\")['dt'].item().seconds/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_005, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>dt</th></tr><tr><td>str</td><td>duration[μs]</td></tr></thead><tbody><tr><td>&quot;D2016.07.02_S1360_I149_3&quot;</td><td>10m 5s 600804µs</td></tr><tr><td>&quot;D2016.10.18_S1418_I149_9&quot;</td><td>15m 1s 502953µs</td></tr><tr><td>&quot;D2016.02.25_S1241_I149_2&quot;</td><td>10m 9s 681058µs</td></tr><tr><td>&quot;D2016.04.19_S1290_I149_8&quot;</td><td>10m 731982µs</td></tr><tr><td>&quot;D2016.03.12_S1256_I149_4&quot;</td><td>10m 9s 750677µs</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;D2016.07.02_S1359_I149_7&quot;</td><td>10m 6s 149155µs</td></tr><tr><td>&quot;D2017.09.21_S1624_I149_2&quot;</td><td>15m 2s 956941µs</td></tr><tr><td>&quot;D2016.05.16_S1310_I149_4&quot;</td><td>10m 10s 44928µs</td></tr><tr><td>&quot;D2016.03.13_S1258_I149_6&quot;</td><td>10m 8s 803783µs</td></tr><tr><td>&quot;D2016.01.05_S1181_I149_4&quot;</td><td>10m 1s 915236µs</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_005, 2)\n",
       "┌──────────────────────────┬─────────────────┐\n",
       "│ id                       ┆ dt              │\n",
       "│ ---                      ┆ ---             │\n",
       "│ str                      ┆ duration[μs]    │\n",
       "╞══════════════════════════╪═════════════════╡\n",
       "│ D2016.07.02_S1360_I149_3 ┆ 10m 5s 600804µs │\n",
       "│ D2016.10.18_S1418_I149_9 ┆ 15m 1s 502953µs │\n",
       "│ D2016.02.25_S1241_I149_2 ┆ 10m 9s 681058µs │\n",
       "│ D2016.04.19_S1290_I149_8 ┆ 10m 731982µs    │\n",
       "│ D2016.03.12_S1256_I149_4 ┆ 10m 9s 750677µs │\n",
       "│ …                        ┆ …               │\n",
       "│ D2016.07.02_S1359_I149_7 ┆ 10m 6s 149155µs │\n",
       "│ D2017.09.21_S1624_I149_2 ┆ 15m 2s 956941µs │\n",
       "│ D2016.05.16_S1310_I149_4 ┆ 10m 10s 44928µs │\n",
       "│ D2016.03.13_S1258_I149_6 ┆ 10m 8s 803783µs │\n",
       "│ D2016.01.05_S1181_I149_4 ┆ 10m 1s 915236µs │\n",
       "└──────────────────────────┴─────────────────┘"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_intervals_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# Example function\n",
    "# def get_inflection_points(area_series):\n",
    "#     # Perform computations here\n",
    "#     return some_result\n",
    "\n",
    "# Parallel processing wrapper\n",
    "def process_group(group):\n",
    "    group_id, group_data, embryo_dt = group\n",
    "    \n",
    "    if embryo_dt.is_empty():\n",
    "        return group_id, 0\n",
    "\n",
    "    if \"dt\" not in embryo_dt.columns:\n",
    "        raise ValueError(f\"Column 'dt' not found in time_intervals_final for id {group_id[0]}\")\n",
    "\n",
    "    # Compute peaks\n",
    "    peaks = get_inflection_points(group_data[\"area\"])\n",
    "\n",
    "    # Ensure dt_in_hours is a scalar or iterable\n",
    "    dt_in_hours = embryo_dt[\"dt\"].item()*1440/60  # Convert to list\n",
    "\n",
    "    # if len(dt_in_hours) != 1:\n",
    "    #     raise ValueError(f\"Expected one dt value per group but found {len(dt_in_hours)} for id {group_id[0]}\")\n",
    "\n",
    "    # Extract the scalar value for dt\n",
    "    dt_in_hours_scalar = dt_in_hours\n",
    "\n",
    "    # Filter peaks\n",
    "    ok_peaks = [peak for peak in peaks if peak * dt_in_hours > 96]\n",
    "\n",
    "    # Return the minimum valid peak\n",
    "    return group_id, min(ok_peaks, default=None)\n",
    "\n",
    "# Extract groups, process in parallel, and reconstruct\n",
    "def parallel_map_groups(df, group_column, time_intervals_final):\n",
    "    grouped = df.group_by(group_column, maintain_order=True)\n",
    "    groups = [\n",
    "        (group_id, group_data, time_intervals_final.filter(pl.col(\"id\") == group_id[0]))\n",
    "        for group_id, group_data in grouped\n",
    "    ]\n",
    "    \n",
    "    # Set process count based on available cores\n",
    "    num_processes = min(len(groups), cpu_count())\n",
    "\n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        results = pool.map(process_group, groups)\n",
    "    \n",
    "    # Filter out groups with no valid peaks\n",
    "    results = [(group_id, corr) for group_id, corr in results if corr is not None]\n",
    "    \n",
    "    # Rebuild the dataframe\n",
    "    return pl.DataFrame({\"id\": [result[0][0] for result in results], \"peak\": [result[1] for result in results]})\n",
    "\n",
    "# Apply to your data\n",
    "peaks_area = parallel_map_groups(final_df, \"id\", time_intervals_final)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(685,)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.filter(pl.col('id')=='D2016.01.11_S1183_I149_4')['area'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_area.write_csv(data_pth/'area_peaks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellforge_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
