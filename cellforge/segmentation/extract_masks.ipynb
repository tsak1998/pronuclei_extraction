{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from typing import Literal\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from PIL.ImageFile import ImageFile\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms as T\n",
    "\n",
    "from dataloader import ImageDataset, TransformWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pth = Path('/Users/tsakalis/ntua/cellforge/data/the_perfect_candidate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_paths = sorted(list((sample_pth).glob('*.jpg')),\n",
    "                          key=lambda x: int(x.stem.split('_')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_tensor = T.Compose([\n",
    "    T.Lambda(lambda x: x.resize(\n",
    "        (image_size, image_size), Image.Resampling.LANCZOS)),\n",
    "    T.Lambda(lambda x: x.convert(\"RGB\")),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    T.Lambda(lambda x: x[:1, :]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = data.DataLoader(\n",
    "    [normalize_tensor(Image.open(img)) for img in image_file_paths[-200:]],\n",
    "    shuffle=False,\n",
    "    batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=1,\n",
    ")\n",
    "\n",
    "whole_model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gb/2dm73f1s22n8755ydqgrblxw0000gn/T/ipykernel_68069/934992615.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(\n",
      "/var/folders/gb/2dm73f1s22n8755ydqgrblxw0000gn/T/ipykernel_68069/934992615.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_model.load_state_dict(\n",
    "    torch.load(\n",
    "        '/Users/tsakalis/ntua/cellforge/cellforge/segmentation/model_weights/inner_embryo.pt'\n",
    "    ))\n",
    "\n",
    "whole_model.load_state_dict(\n",
    "    torch.load(\n",
    "        '/Users/tsakalis/ntua/cellforge/cellforge/segmentation/model_weights/full_embryo.pt'\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'mps'\n",
    "\n",
    "inner_model.eval()\n",
    "whole_model.eval()\n",
    "\n",
    "inner_model.to(device)\n",
    "whole_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:16<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "all_zps = []\n",
    "for batch in tqdm(dataloader):\n",
    "\n",
    "    mask_inner = torch.sigmoid(inner_model(batch.to(device)))\n",
    "    mask_whole = torch.sigmoid(whole_model(batch.to(device)))\n",
    "\n",
    "    zps = mask_whole - mask_inner\n",
    "\n",
    "    all_zps.append(tensor_to_numpy(zps))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_zps_ar = np.vstack(all_zps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_arr_normalized = ((all_zps_ar + 1) / 2) * 255\n",
    "threshold = 128\n",
    "binary_mask = (tensor_arr_normalized > threshold).astype(np.uint8) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as output_video.mp4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Assume `tensor` is your NumPy array of shape (150, 1, 224, 224)\n",
    "tensor_arr_normalized = ((all_zps_ar + 1) / 2) * 255\n",
    "threshold = 128\n",
    "binary_mask = (tensor_arr_normalized > threshold).astype(np.uint8) * 255\n",
    "frames = np.squeeze(binary_mask, axis=1)\n",
    "\n",
    "# Define the output video parameters\n",
    "output_file = 'output_video.mp4'\n",
    "frame_height, frame_width = frames.shape[1], frames.shape[2]\n",
    "fps = 20  # Frames per second\n",
    "\n",
    "# Define video codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # 'mp4v' for .mp4\n",
    "out = cv2.VideoWriter(output_file,\n",
    "                      fourcc,\n",
    "                      fps, (frame_width, frame_height),\n",
    "                      isColor=False)\n",
    "\n",
    "# Write each frame to the video\n",
    "for frame in frames:\n",
    "    out.write(frame)\n",
    "\n",
    "# Release the VideoWriter\n",
    "out.release()\n",
    "\n",
    "print(f\"Video saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF saved as output_animation.gif\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Assuming `tensor_arr` is your NumPy array with shape (150, 1, 224, 224) in range [-1, 1]\n",
    "\n",
    "# Step 3: Remove the channel dimension to get (150, 224, 224)\n",
    "frames = np.squeeze(binary_mask, axis=1)\n",
    "\n",
    "# Step 4: Convert each frame to a Pillow Image and save as GIF\n",
    "images = [Image.fromarray(frame, mode='L')\n",
    "          for frame in frames]  # 'L' mode for grayscale\n",
    "output_gif = 'output_animation.gif'\n",
    "images[0].save(\n",
    "    output_gif,\n",
    "    save_all=True,\n",
    "    append_images=images[1:],\n",
    "    duration=100,  # Duration for each frame in milliseconds (adjust as needed)\n",
    "    loop=0  # Loop forever (set to `1` for no looping)\n",
    ")\n",
    "\n",
    "print(f\"GIF saved as {output_gif}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=224x224>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[-10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
